{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foreshock–Aftershock Evaluation (SeisLM-style)\n",
    "\n",
    "This notebook loads a fine-tuned checkpoint, runs evaluation on the foreshock–aftershock test split, and plots a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7baa39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: adjust working directory and imports\n",
    "import os, sys\n",
    "base_dir = os.path.abspath(os.path.join(os.getcwd()))\n",
    "if os.path.basename(base_dir) != 'seismic_data_modeling':\n",
    "    # Try to locate project root ending with 'seismic_data_modeling'\n",
    "    parts = base_dir.split(os.sep)\n",
    "    if 'seismic_data_modeling' in parts:\n",
    "        idx = parts.index('seismic_data_modeling')\n",
    "        proj = os.sep.join(parts[:idx+1])\n",
    "        os.chdir(proj)\n",
    "        base_dir = proj\n",
    "\n",
    "sys.path.insert(0, base_dir)\n",
    "print('Project dir:', base_dir)\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dataloaders.foreshock_aftershock_lit import ForeshockAftershockLitDataset\n",
    "from simple_train import load_checkpoint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58614e42",
   "metadata": {},
   "source": [
    "**Note:** The pretraining (contrastive) checkpoint initializes the backbone before finetuning.\n",
    "For evaluation here, we load the finetuned foreshock checkpoint only.\n",
    "\n",
    "- Pretraining ckpt (for finetune init):\n",
    "  `/path/to/your/checkpoint_or_data\n",
    "- Foreshock finetuned ckpt (for eval):\n",
    "  `/path/to/your/checkpoint_or_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60f40ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths and config\n",
    "DATA_DIR = '/path/to/your/checkpoint_or_data'\n",
    "# Use FINETUNED foreshock checkpoint for evaluation (not the pretraining ckpt)\n",
    "CKPT_PATH = '/path/to/your/checkpoint_or_data'\n",
    "NUM_CLASSES = 9\n",
    "BATCH_SIZE = 32  # evaluation batch size\n",
    "\n",
    "print('Using DATA_DIR:', DATA_DIR)\n",
    "print('Using FINETUNED CKPT_PATH:', CKPT_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f56349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build test dataloader (mirrors training pipeline)\n",
    "ds = ForeshockAftershockLitDataset(\n",
    "    data_dir=DATA_DIR,\n",
    "    num_classes=NUM_CLASSES,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    event_split_method='temporal',\n",
    "    component_order='ZNE',\n",
    "    seed=42,\n",
    "    remove_class_overlapping_dates=False,\n",
    "    train_frac=0.7,\n",
    "    val_frac=0.10,\n",
    "    test_frac=0.20,\n",
    "    dimension_order='NWC',  # match training setup\n",
    "    demean_axis=1,\n",
    "    amp_norm_axis=1,\n",
    "    amp_norm_type='std',\n",
    "    num_workers=0,\n",
    "    collator=None,\n",
    ")\n",
    "test_loader = ds.test_loader\n",
    "len(test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea944152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model from finetuned checkpoint using Hydra-composed config\n",
    "from hydra import initialize, compose\n",
    "from simple_train import load_checkpoint\n",
    "# Compose full config with defaults resolved\n",
    "with initialize(config_path='configs', version_base=None):\n",
    "    cfg = compose(config_name='config.yaml', overrides=[\n",
    "        'experiment=fore_aftershock/finetune_xlstm_unet',\n",
    "        'train.disable_pretraining=true',\n",
    "    ])\n",
    "model, _ = load_checkpoint(CKPT_PATH, updated_model_config=cfg, d_data=3)\n",
    "# Ensure classification\n",
    "try:\n",
    "    model.model.pretraining=False\n",
    "    model.encoder.pretraining=False\n",
    "except Exception:\n",
    "    pass\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model.to(device).eval()\n",
    "print('Model loaded via Hydra-composed config on', device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ed45c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate: collect predictions and compute loss/accuracy (with basic debug)\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "total_loss = 0.0\n",
    "n_samples = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (x, y) in enumerate(tqdm(test_loader, desc='Testing')):\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        try:\n",
    "            logits, targets = model.forward((x, y), batch_idx)\n",
    "        except Exception as e:\n",
    "            print('[error] forward failed at batch', batch_idx, e)\n",
    "            print('x shape:', tuple(x.shape), 'y shape:', tuple(y.shape))\n",
    "            raise\n",
    "        loss = F.cross_entropy(logits, targets)\n",
    "        total_loss += loss.item() * targets.shape[0]\n",
    "        n_samples += targets.shape[0]\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        all_preds.append(preds.detach().cpu().numpy())\n",
    "        all_targets.append(targets.detach().cpu().numpy())\n",
    "\n",
    "all_preds = np.concatenate(all_preds, axis=0)\n",
    "all_targets = np.concatenate(all_targets, axis=0)\n",
    "test_loss = total_loss / max(1, n_samples)\n",
    "test_acc = accuracy_score(all_targets, all_preds)\n",
    "print(f'Test Loss: {test_loss:.4f}  |  Test Acc: {test_acc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(all_targets, all_preds, labels=list(range(NUM_CLASSES)))\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=list(range(NUM_CLASSES)))\n",
    "disp.plot(ax=ax, cmap='Blues', colorbar=True)\n",
    "plt.title('Foreshock–Aftershock Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (xlstm_official_240)",
   "language": "python",
   "name": "xlstm_official_240"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
